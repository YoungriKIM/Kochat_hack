{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 라이브러리"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import os\r\n",
    "import platform\r\n",
    "import torch\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import LinearSVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 경로설정"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# --------------------------------------------------------\r\n",
    "# 7번째 줄\r\n",
    "root_dir = os.path.abspath(os.curdir)\r\n",
    "print(root_dir) # d:\\yespeechcode\\kochat\\yr_hack\r\n",
    "# 현재 있는 폴더 경로 반환. curdir = current directory\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# 13, 14 줄\r\n",
    "_ = '\\\\' if platform.system() == 'Windows' else '/'\r\n",
    "print(_)    # \\\r\n",
    "# 시스템 플랫폼이 윈도우일 때는 파일경로에 \\\\를 사용 , 리눅스 일 때는 / 사용\r\n",
    "\r\n",
    "if root_dir[len(root_dir) - 1] != _: root_dir += _\r\n",
    "print(root_dir) # d:\\yespeechcode\\kochat\\yr_hack\\\r\n",
    "# 위에서 받은 root_dir이 \\로 아닌 문자로 끝나면 끝에 \\를 붙여주기"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "d:\\yespeechcode\\kochat\\yr_hack\n",
      "\\\n",
      "d:\\yespeechcode\\kochat\\yr_hack\\\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 16 줄, BASE  \r\n",
    "하나씩 주석 달기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BASE = {\r\n",
    "    'root_dir': root_dir.format(_=_),  # 백엔드 루트경로\r\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\r\n",
    "    'vector_size': 128,  # 단어 벡터 사이즈\r\n",
    "    'batch_size': 512,  # 미니배치 사이즈\r\n",
    "    'max_len': 8,  # 문장의 최대 길이 (패드 시퀀싱)\r\n",
    "    'delimeter': _,  # OS에 따른 폴더 delimeter\r\n",
    "\r\n",
    "    'PAD': 0,  # PAD 토큰 값 (전체가 0인 벡터)\r\n",
    "    'OOV': 1  # OOV 토큰 값 (전체가 1인 벡터)\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# ===================\r\n",
    "root_dir.format(_=_)\r\n",
    "# ===================\r\n",
    "\r\n",
    "# 현재 있는 경로를 백엔드로 지정\r\n",
    "# kochat_config.py 에서 28번 DATA에 사용"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'d:\\\\yespeechcode\\\\kochat\\\\yr_hack\\\\'"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'device': 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "# ===================\r\n",
    "\r\n",
    "# cuda gpu 사용가능하면 cuda 아니면 cpu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'vector_size': 128,  # 단어 벡터 사이즈\r\n",
    "# ===================\r\n",
    "\r\n",
    "# word_embedding의 대표적인 기법인 Word2vec 과 fasttext\r\n",
    "# 참고: https://inspiringpeople.github.io/data%20analysis/word_embedding/\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/model/embed/word2vec.py 19번\r\n",
    "class Word2Vec(Word2Vec):\r\n",
    "    def __init__(self):\r\n",
    "        \"\"\"\r\n",
    "        Gensim Word2Vec 모델의 Wrapper 클래스입니다.\r\n",
    "        \"\"\"\r\n",
    "        super().__init__(size=self.vector_size,         # word 벡터 차원(embedding size)\r\n",
    "                         window=self.window_size,       # 현재 단어와 예측 단어의 최대 거리\r\n",
    "                         workers=self.workers,          # 모델 생성시 사용할 thread 수\r\n",
    "                         min_count=self.min_count,      # min_count 빈도수도다 낮은 빈도수 단어는 무시\r\n",
    "                         iter=self.iter)                # 학습 횟수\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/model/embed/fasttext.py 19번\r\n",
    "class FastText(FastText):\r\n",
    "    def __init__(self):\r\n",
    "        \"\"\"\r\n",
    "        Gensim Word2Vec 모델의 Wrapper 클래스입니다.\r\n",
    "        \"\"\"\r\n",
    "        super().__init__(size=self.vector_size,\r\n",
    "                         window=self.window_size,\r\n",
    "                         workers=self.workers,\r\n",
    "                         min_count=self.min_count,\r\n",
    "                         iter=self.iter)\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/model/entity/lstm.py 21번\r\n",
    "self.lstm = nn.LSTM(input_size=self.vector_size ... \r\n",
    "# kochat/model/intent/lstm.py 28번\r\n",
    "self.lstm = nn.LSTM(input_size=self.vector_size ...\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/proc/intent_classifier.py 64번\r\n",
    "sample = torch.randn(1, self.max_len, self.vector_size)\r\n",
    "# torch.randn() : 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 생성\r\n",
    "# 사이즈를 (1, max_len, vector_size)로 생성\r\n",
    "\r\n",
    "# kochat/proc/entity_recognizer.py 144번\r\n",
    "sample = torch.randn(1, self.max_len, self.vector_size)\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/proc/gensim_embedder.py 94번\r\n",
    "word_vector = torch.ones(self.vector_size) * self.OOV\r\n",
    "# word_vactor 사이즈를 vector_size로 맞추고 OOV 값 곱하기          # 'OOV': 1\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/preprocessor.py 49번\r\n",
    "pad = torch.ones(self.max_len, self.vector_size) * self.PAD\r\n",
    "# 문장이 max_len보다 짧으면 길이가 max_len인 0벡터를 만들기         # 'PAD': 0\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'batch_size': 512,  # 미니배치 사이즈\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/model/entity/lstm.py 27번\r\n",
    "param1 = torch.randn(self.layers * self.direction, batch_size, self.d_model).to(self.device)\r\n",
    "# kochat/model/intent/lstm.py 34번\r\n",
    "param1 = torch.randn(self.layers * self.direction, batch_size, self.d_model).to(self.device)\r\n",
    "# entity, Intent Classification을 위한 LSTM 클래스\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/dataset.py 290번\r\n",
    "return DataLoader(\r\n",
    "        dataset=TensorDataset(*tensors),\r\n",
    "        batch_size=self.batch_size,\r\n",
    "        shuffle=True,\r\n",
    "        pin_memory=True     # True러 선언하면, 데이터로더는 Tensor를 CUDA 고정 메모리에 올립니다.\r\n",
    "    )\r\n",
    "# pytorch에서 제공하는 DaraLoader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'max_len': 8,  # 문장의 최대 길이 (패드 시퀀싱)\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/preprocessor.py 43번\r\n",
    "def pad_sequencing(self, sequence: Tensor) -> tuple:\r\n",
    "    \"\"\"\r\n",
    "    패드 시퀀싱 함수입니다.\r\n",
    "    max_len보다 길이가 길면 자르고, 짧으면 뒤에 패딩(영벡터)를 추가합니다.\r\n",
    "    엔티티 학습시에 CRF나 Masking 등을 이용하기 위해 각 문장의 길이가 필요합니다.\r\n",
    "    패드 시퀀싱 단계에서는 어차피 길이를 세기 때문에 길이를 함께 반환합니다.\r\n",
    "    :param sequence: 패드 시퀀싱할 문장입니다. (tensor로 이미 임베딩 된 문장)\r\n",
    "    :return: 패드시퀀싱된 문장과 시퀀싱 전의 문장의 원래 길이\r\n",
    "    \"\"\"\r\n",
    "    length = sequence.size()[0]\r\n",
    "    if length > self.max_len:\r\n",
    "        sequence = sequence[:self.max_len]\r\n",
    "        length = self.max_len  # 마스킹시에 길이가 max_len 넘어가면 안됨\r\n",
    "        # 문장이 max_len보다 길면 뒷부분을 자릅니다.\r\n",
    "    else:\r\n",
    "        pad = torch.ones(self.max_len, self.vector_size) * self.PAD\r\n",
    "        for i in range(length):\r\n",
    "            pad[i] = sequence[i]\r\n",
    "        sequence = pad\r\n",
    "        # 문장이 max_len보다 짧으면 길이가 max_len인 0벡터를 만들고\r\n",
    "        # 데이터가 있던 인덱스에는 원래 데이터를 복사합니다\r\n",
    "    return sequence, length\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/loss/utils/masking.py 11번\r\n",
    "# kochat/loss/masking.py 13번\r\n",
    "class Masking(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        \"\"\"\r\n",
    "        시퀀스 길이를 받아서 max_len 길이의 마스킹 벡터들의 집합을 만듭니다.\r\n",
    "        e.g. sequence_length = 3,\r\n",
    "        [True, True, True, False, False , ..., False]\r\n",
    "        \"\"\"\r\n",
    "        super().__init__()\r\n",
    "    def forward(self, sequence_length: Tensor) -> Tensor:\r\n",
    "        batch_size = sequence_length.size(0)\r\n",
    "        masks = []\r\n",
    "        for i in range(batch_size):\r\n",
    "            mask = torch.zeros(self.max_len, dtype=torch.uint8).to(self.device)\r\n",
    "            # 전부다 0으로 된 마스킹 벡터 생성\r\n",
    "            for j in range(sequence_length[i]):\r\n",
    "                # seq length까지만 1로 만들어줌\r\n",
    "                mask[j] = 1\r\n",
    "            masks.append(mask.unsqueeze(0))\r\n",
    "            # 마스크 배열에 넣어줌\r\n",
    "        return torch.cat(masks, dim=0)\r\n",
    "        # batchwise concatenation\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/proc/intent_classifier.py 64번\r\n",
    "# kochat/proc/entity_recognizer.py 144번\r\n",
    "sample = torch.randn(1, self.max_len, self.vector_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'delimeter': _  # OS에 따른 폴더 delimeter(구분자)\r\n",
    "# 윗 줄에서 window라면 \\\\으로 linux면 /으로 지정됨\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/proc/base_processor.py 27번\r\n",
    "self.model_dir = self.model_dir + \\\r\n",
    "                 self.__class__.__name__ + \\\r\n",
    "                 self.delimeter\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/utils/visualizer.py 281번\r\n",
    "# kochat/proc/utils/visualizer.py 281번\r\n",
    "f = open(self.model_dir + 'temp{_}{mode}.txt'.format(_=self.delimeter, mode=mode), 'r')\r\n",
    "file = f.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 29번 DATA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATA = {\r\n",
    "    'data_ratio': 0.8,  # 학습\\\\검증 데이터 비율\r\n",
    "    'raw_data_dir': BASE['root_dir'] + \"data{_}raw{_}\".format(_=_),  # 원본 데이터 파일 경로\r\n",
    "    'ood_data_dir': BASE['root_dir'] + \"data{_}ood{_}\".format(_=_),  # out of distribution 데이터셋\r\n",
    "    'intent_data_dir': BASE['root_dir'] + \"data{_}intent_data.csv\".format(_=_),  # 생성된 인텐트 데이터 파일 경로\r\n",
    "    'entity_data_dir': BASE['root_dir'] + \"data{_}entity_data.csv\".format(_=_),  # 생성된 엔티티 데이터 파일 경로\r\n",
    "\r\n",
    "    'NER_categories': ['DATE', 'LOCATION', 'RESTAURANT', 'PLACE'],  # 사용자 정의 태그\r\n",
    "    'NER_tagging': ['B', 'E', 'I', 'S'],  # NER의 BEGIN, END, INSIDE, SINGLE 태그\r\n",
    "    'NER_outside': 'O',  # NER의 O태그 (Outside를 의미)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'data_ratio': 0.8,  # 학습\\\\검증 데이터 비율\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/dataset.py 239번\r\n",
    "def __split_data(self, dataset: list) -> tuple:\r\n",
    "    \"\"\"\r\n",
    "    데이터셋을 학습용 / 검증용으로 나눕니다.\r\n",
    "    Configuration에 적힌 split ratio를 기준으로 데이터를 쪼갭니다.\r\n",
    "    :param dataset: 토큰화가 완료된 리스트 데이터셋\r\n",
    "    :return: 분리가 완료된 (학습용 데이터, 검증용 데이터)\r\n",
    "    \"\"\"\r\n",
    "    random.shuffle(dataset)  # 데이터 섞어주기\r\n",
    "    split_point = int(len(dataset) * self.data_ratio)   #####\r\n",
    "    train_dataset = dataset[:split_point]\r\n",
    "    test_dataset = dataset[split_point:]\r\n",
    "    return train_dataset, test_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'raw_data_dir': BASE['root_dir'] + \"data{_}raw{_}\".format(_=_),  # 원본 데이터 파일 경로\r\n",
    "'ood_data_dir': BASE['root_dir'] + \"data{_}ood{_}\".format(_=_),  # out of distribution 데이터셋\r\n",
    "'intent_data_dir': BASE['root_dir'] + \"data{_}intent_data.csv\".format(_=_),  # 생성된 인텐트 데이터 파일 경로\r\n",
    "'entity_data_dir': BASE['root_dir'] + \"data{_}entity_data.csv\".format(_=_),  # 생성된 엔티티 데이터 파일 경로\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# 파일 경로"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'NER_categories': ['DATE', 'LOCATION', 'RESTAURANT', 'PLACE'],  # 사용자 정의 태그\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/app/scenario.py 42번\r\n",
    "pre_defined_entity = [entity.lower() for entity in self.NER_categories]\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/organizer.py 153번\r\n",
    "label = [tag + '-' + cate\r\n",
    "         for cate in self.NER_categories\r\n",
    "         for tag in self.NER_tagging] + [self.NER_outside]\r\n",
    "         # Config에서 지정한 라벨들의 조합 + Outside 라벨만 가질 수 있음\r\n",
    "\r\n",
    "# entity 예 )\r\n",
    "# 게다가 광명 우산 가져가야하니,O S-LOCATION O O\r\n",
    "# 아 울산 이번 주 비 오니,O S-LOCATION B-DATE E-DATE O O"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'NER_tagging': ['B', 'E', 'I', 'S'],  # NER의 BEGIN, END, INSIDE, SINGLE 태그\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/organizer.py 154번\r\n",
    "label = [tag + '-' + cate\r\n",
    "         for cate in self.NER_categories\r\n",
    "         for tag in self.NER_tagging] + [self.NER_outside]\r\n",
    "         # Config에서 지정한 라벨들의 조합 + Outside 라벨만 가질 수 있음\r\n",
    "\r\n",
    "# entity 예 )\r\n",
    "# 게다가 광명 우산 가져가야하니,O S-LOCATION O O\r\n",
    "# 아 울산 이번 주 비 오니,O S-LOCATION B-DATE E-DATE O O"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ===================\r\n",
    "'NER_outside': 'O',  # NER의 O태그 (Outside를 의미)\r\n",
    "# ===================\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/organizer.py 154번\r\n",
    "label = [tag + '-' + cate\r\n",
    "         for cate in self.NER_categories\r\n",
    "         for tag in self.NER_tagging] + [self.NER_outside]\r\n",
    "         # Config에서 지정한 라벨들의 조합 + Outside 라벨만 가질 수 있음\r\n",
    "\r\n",
    "# entity 예 )\r\n",
    "# 게다가 광명 우산 가져가야하니,O S-LOCATION O O\r\n",
    "# 아 울산 이번 주 비 오니,O S-LOCATION B-DATE E-DATE O O\r\n",
    "\r\n",
    "# --------------------------------------------------------\r\n",
    "# kochat/data/preprocessor.py 79번\r\n",
    "def label_sequencing(self, entity_label: Tensor, entity_dict: dict) -> Tensor:\r\n",
    "    \"\"\"\r\n",
    "    엔티티 라벨의 경우에는 라벨도 각각 길이가 다르게 됩니다.\r\n",
    "    e.g. [O, DATE, O](size=3),  [DATE, O, O, O](size=4)\r\n",
    "    길이가 다른 벡터들을 텐서의 형태로 만들려면 이들의 길이도 같아야합니다.\r\n",
    "    :param entity_label: 한 문장의 엔티티 라벨 (1차원)\r\n",
    "    :param entity_dict: 딕셔너리를 이용해 빈부분에 outside 태그를 넣습니다.\r\n",
    "    :return: 패드시퀀싱 된 엔티티 라벨\r\n",
    "    \"\"\"\r\n",
    "    length = entity_label.size()[0]\r\n",
    "\r\n",
    "    if length > self.max_len:\r\n",
    "        entity_label = entity_label[:self.max_len]\r\n",
    "        # 길이가 max_len보다 길면 뒷부분을 자릅니다.\r\n",
    "\r\n",
    "    else:\r\n",
    "        pad = torch.ones(self.max_len, dtype=torch.int64)\r\n",
    "        outside_tag = entity_dict[self.NER_outside]\r\n",
    "        pad = pad * outside_tag  # 'O' 태그가 맵핑된 숫자       ##########\r\n",
    "        # [1, 1, ..., 1] * 'O' => ['O', 'O', ... , 'O']\r\n",
    "\r\n",
    "        for i in range(length):\r\n",
    "            pad[i] = entity_label[i]\r\n",
    "        entity_label = pad\r\n",
    "        # 문장이 max_len보다 짧으면 길이가 max_len인 'O'벡터를 만들고\r\n",
    "        # 데이터가 있던 인덱스에는 원래 데이터를 복사합니다\r\n",
    "\r\n",
    "    return entity_label.unsqueeze(0)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}